{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)  # نقوم بتثبيت جذر نموذج الأرقام العشوائية، حتى نحصل على نفس النتائج كل مرة نشغل البرنامج"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# تجدون البيانات في رابط أدناه\n",
    "# https://www.kaggle.com/kazanova/sentiment140/data#\n",
    "data = pd.read_csv(\"2477_4140_compressed_training.1600000.processed.noemoticon/training.1600000.processed.noemoticon.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['sentiment', 'tweet id', 'time', 'query', 'username', 'tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet id</th>\n",
       "      <th>time</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment    tweet id                          time     query  \\\n",
       "0          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "        username                                              tweet  \n",
       "0  scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2        ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3         Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4       joy_wolf                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   sentiment  1599999 non-null  int64 \n",
      " 1   tweet id   1599999 non-null  int64 \n",
      " 2   time       1599999 non-null  object\n",
      " 3   query      1599999 non-null  object\n",
      " 4   username   1599999 non-null  object\n",
      " 5   tweet      1599999 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    799999\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# الآن سنقوم بقراءة النصوص و حفظها في قائمتين\n",
    "# نقوم بإنشاء قائمتين لملئها بالنصوص\n",
    "negative_texts = []  # السلبية\n",
    "positive_texts = []  # الإيجابية"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    يجري هنا تجهيز النص من خلال مسح الرموز و محاولة تبسيطه\n",
    "    :param text: النص المدخل من نوع str\n",
    "    :return: النص بعد تجهيزه\n",
    "    '''\n",
    "    \n",
    "    text = text.lower()\n",
    "    # حذف حسابات المستخدمين\n",
    "    text = re.sub(\"@[a-z0-9_]+\", ' ', text)\n",
    "    # حذف الروابط\n",
    "    text = re.sub(\"[^ ]+\\.[^ ]+\", ' ', text)\n",
    "    # حذف البريد الالكتروني\n",
    "    text = re.sub(\"[^ ]+@[^ ]+\\.[^ ]\", ' ', text)\n",
    "    # حذف الأرقام و الرموز\n",
    "    text = re.sub(\"[^a-z\\' ]\", ' ', text)\n",
    "    # حذف المسافات الزائدة\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if data['sentiment'][i] == 0:\n",
    "        negative_texts.append(clean_text(data['tweet'][i]))\n",
    "    else:\n",
    "        positive_texts.append(clean_text(data['tweet'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عدد النصوص الإيجابية:\n",
      "800000\n",
      "عدد النصوص السلبية:\n",
      "799999\n"
     ]
    }
   ],
   "source": [
    "print(\"عدد النصوص الإيجابية:\")\n",
    "print(len(positive_texts))\n",
    "print(\"عدد النصوص السلبية:\")\n",
    "print(len(negative_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ننشئ قائمتين إضافيتين للتصنيفات\n",
    "# سنرمز للتصنيف الٌيجابي بصفر و التصنيف السلبي بواحد\n",
    "''' هكذا سيكون تصنيف النص الإيجابي رقم س في قائمة النصوص الإٌيجابية موجودًا في المكان رقم س أيضا في قاذمة تصنيفات النصوص \n",
    "الإيجابية، و نفس الشيء بالنسبة للنصوص السلبية'''\n",
    "\n",
    "positive_labels = [1]*len(positive_texts)  # قائمة تصنيفات النصوص الإيجابية\n",
    "negative_labels = [0]*len(negative_texts)  # قائمة تصنيفات النصوص السلبية\n",
    "\n",
    "all_texts = positive_texts + negative_texts  # نضع جميع النصوص في قائمة واحدة\n",
    "all_labels = positive_labels + negative_labels  # نضع التصنيفات في قائمة واحدة بنفس الترتيب"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عدد النصوص يساوي عدد التصنيفات؟\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"عدد النصوص يساوي عدد التصنيفات؟\")\n",
    "print(len(all_labels) == len(all_texts))  # لابد أن يكون لهما نفس العدد حيث يكون لكل نص تصنيف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# لاحظ أن النصوص الإيجابية جميعها في البداية و السلبية جميعها في النهاية\n",
    "# لذا سنقوم بتغيير ترتيب النصوص بشكل عشوائي (مع تصنيفاتها)\n",
    "# هذه الدالة من مكتبة إس كي ليرن ستقوم بتغيير أماكن النصوص عشوائيا مع مراعاة ارتباط كل نص بتصنيفه\n",
    "# يمكن إدخال أي عدد من القوائم أو المصفوفات بشرط أن يكون لها نفس الطول\n",
    "from sklearn.utils import shuffle  # نستدعي الدالة\n",
    "all_texts, all_labels = shuffle(all_texts, all_labels)  # نشغلها، يجب مراعاة الترتيب للحصول على نتائج صحيحة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# سنكون بحاجة إلى لمعرفة مدى جودة أداء النموذج بعد تدريبه، أي سنحتاج لمجموعة مصنفة من النصوص لنختبر النموذج\n",
    "# لذا نقسم البيانات لقسمين، قسم للاختبار و قسم للتدريب\n",
    "# يمثل قسم التدريب ٢٠٪ من حجم النصوص الآصلي\n",
    "# سنسخدم دالة train_test_split من إس كي ليرن، تقوم هذه الدالة بتقسيم النصوص و التصنيفات\n",
    "# يمكن إدخال أي عدد من القوائم أو المصفوفات إلى هذه الدالة\n",
    "# لاحظ أنك لو أدخلت س من القوائم/المصفوفات فإنك ستحصل على ٢*س من القوائم/المصفوفات\n",
    "from sklearn.model_selection import train_test_split  # نستدعي الدالة\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_texts, all_labels, test_size=0.20)  # نشغلها، لاحظ الترتيب\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# النص الآن جائز للتدريب، ما عدا ￿أن شكله الطبيعي غير مقبول بالنسبة للنموذج، لذا سنقوم باستخراج الميزات\n",
    "# كما ذكرنا سابقًا، أحد أبرز الطرق لاستخراج الميزات هي تحوسل الكلمة لرقم count vectorization\n",
    "# سنسخدم نموذج CountVecotrizer من مكتبة sklearn لتحويل الكلمات ￿لأرقام، و هكذا سنكون قد استخرجنا الميزات\n",
    "# يوفر هذا النموج أيضا بعض طرق اختيار الميزات، كحذف الكلمات النادرة مثلا\n",
    "# لكننا سنستخدم جميع الميزات بسبب قلة بيانات التدريب\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # نستدعي count vectorizer\n",
    "vectorizer = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', min_df=1)  # نقوم بتعريفه، نرغب هنا بأن يستخدم الكلمات كميزات\n",
    "# نقوم بتدريبه على نصوص التدريب، هذه الخطوة ستجعله يستخرج الكلمات و يرقمها كميزات\n",
    "vectorizer.fit(x_train)\n",
    "# ثم نحول نصوص التدريب باستخدامه، هذه الخطوة ستجعله ينشئ مصفوفة أعمدتها الميزات و صفوفها النصوص\n",
    "# سيملأ كل صف بعدد المرات التي ذكرت فيها الميزة/الكلمة  في اعمود المترتبط في النص المقصود\n",
    "x_train = vectorizer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# لدينا الآن بيانات جاهزة للتدريب، سنحتاج خوارزمية لنستخدمها في تدريب النموذج\n",
    "# يمكننا الاستعانة بهذه الخريطة الإرشادية لاختيار الخوارزمية الملائمة\n",
    "# https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "# ذكرت الخريطة الارشادية سابقا أن خوارزميتي LinearSVC و Naive Bayes يوصى بهما للاستخدام مع النصوص\n",
    "# سنجرب استخدام خوارزمية naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB  # نستدعي نموذج خوارزمية naive bayes\n",
    "model = MultinomialNB()  # نعرف النمذوج باستخدام نموذج خوارزمية إس في إم\n",
    "model.fit(x_train, y_train)  # نقوم بتدريب النموذج، هذه الخطوة قد تتطلب بعض الوقت عند التشغيل بحسب حجم البيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " نسبة الصحة باستخدام خوارزمية نايف بيز :\n",
      "0.779878125\n"
     ]
    }
   ],
   "source": [
    "# نحتاج ￿لمعرفة مدى جودة التدريب، لذا سنقوم باختبار النموذج على نصوص التدريب\n",
    "# سنستخدم دالة تقييم لتحسب لنا نسبة صحة إجابات النموذج مقارنة بالتصنيفات الحقيقة\n",
    "from sklearn.metrics import accuracy_score  # نستدعي دالة التقييم\n",
    "# نحول نصوص الاختبار إلي أرقام باستخدام count vectorizer الذي تم بناؤه على نصوص التدريب سابقا\n",
    "x_test = vectorizer.transform(x_test)\n",
    "# ثم نسخدم النموذج ليتنبأ بتصنيفات النصوص، لاحظ أننا نحتفظ بالتصنيفات الحقيقة أعلاه في المتغير y_test\n",
    "predictions = model.predict(x_test)\n",
    "print(\" نسبة الصحة باستخدام خوارزمية نايف بيز :\")\n",
    "print(accuracy_score(y_test, predictions))  # نقيم أداء النموذج بإرسال التصنيفات الحقيقية و تصنيفات النموذج\n",
    "# حصلنا على نتيجة ٧٧٪، أي أن النموذج استطاع أن يتنبأ بشكل صحيح على ٧٧٪ من بيانات الاختبار\n",
    "# تعتبر هذه النتيجة مقبولة نوعًا ما، لكن يمكننا تجربة خوارزمية أخرى"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nana5\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# سنجرب إس في إم\n",
    "# ستسغرق هذه الخوارزمية وقتًا أطول في التدريب\n",
    "from sklearn.svm import LinearSVC  # نستدعيها\n",
    "model = LinearSVC()  # نعيد تعريف النموذج باستخدام هذه الخوارزمية\n",
    "model.fit(x_train, y_train)  # نقوم بتدريب النموذج"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نسبة الصحة باستخدام خوارزمية إس في إم :\n",
      "0.786875\n"
     ]
    }
   ],
   "source": [
    "# الآن نقوم باختبار النموذج مرة أخرى\n",
    "predictions = model.predict(x_test)\n",
    "print(\"نسبة الصحة باستخدام خوارزمية إس في إم :\")\n",
    "print(accuracy_score(y_test, predictions))\n",
    "# حصلنا على نتيجة ٧٨٪ و هي أفضل من نتيجة الخوارزمية السابقة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# قد ترغب بحفظ النموذج لاستخدامه لاحقًا\n",
    "# تستخدم مكتبة بيكل pickle لحفظ أي متغير\n",
    "# يشترط في هذه المكتبة أن يتم حفظ المتغير و تحميله باستخدام نفس النسخة من المكتبات\n",
    "# سنقوم بحفظ النموذج باستخدامها\n",
    "# لاحظ أن النموذج لن يقبل أي شكل من المصفوفات غير الذي تدرب عليه، لذا يتوجب استخدام نفس ال vectorizer\n",
    "# لذا سنقوم بحفظ نفس الvectorizer الذي تم بناوه على بيانات التدريب\n",
    "import pickle\n",
    "# نقوم بفتح ملف بالاسم المطلوب للنموذج و نخصص الرمز wb للكتابة\n",
    "with open('model.pickle', 'wb') as file:\n",
    "    pickle.dump(model, file)  # تم الحفظ\n",
    "# نكرر الأمر للvectorizer باسم ملف مختلف طبعًا\n",
    "# نقوم بفتح ملف بالاسم المطلوب للvectorizer و نخصص الرمز wb للكتابة\n",
    "with open('vectorizer.pickle', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)  # تم الحفظ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# لتحميل النموذج و الvectorizer بعد الحفظ نستخدم نفس المكتبة\n",
    "# نقوم بفتح ملف النموذج بوضع القراءة rb\n",
    "with open('model.pickle', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "# نكرر الأمر لملف ال vectorizer\n",
    "with open('vectorizer.pickle', 'rb') as file:\n",
    "    vectorizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تصنيف الجملة: I am so happy, the picnic was amazing and the weather was great\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# سنقوم الآن باستخدام النموذج للحصول على تصنيف نص خارجي\n",
    "# مثلا هذا النص\n",
    "example_test = 'I am so happy, the picnic was amazing and the weather was great'\n",
    "# يتوجب تنظيف النص بنفس الطريقة التي تم باستخدامها تنظيف بيانات التدريب\n",
    "cleaned_example_test = clean_text(example_test)\n",
    "#ثم سنقوم بتحويل النص إلى أرقام باستخدام الvectorizer الذي أنشئناه سابقًا\n",
    "# لاحظ أننا سنضع النص داخل مصفوفة ليقبلها، و هذا يعني أنه يمكن إرسال مجموعة من النصوص في مصفوفة كما حدث في بيانات الاختبار سابقا\n",
    "example_test_vector = vectorizer.transform([cleaned_example_test])\n",
    "# أخيرا ندخل المصفوفة الناتجة إلى النموذج\n",
    "example_result = model.predict(example_test_vector)\n",
    "print(\"تصنيف الجملة:\", example_test)\n",
    "print(example_result[0])  # سيكون العنصر الأول بطبيعة الحال كوننا لم ندخل سوى جملة واحدة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
